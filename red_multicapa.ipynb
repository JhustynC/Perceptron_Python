{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(csv_path):\n",
    "    try:\n",
    "        data = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: El archivo no se encontró.\")\n",
    "        return None, None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: El archivo está vacío.\")\n",
    "        return None, None\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error: Error al analizar el archivo.\")\n",
    "        return None, None\n",
    "    \n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características: 25\n"
     ]
    }
   ],
   "source": [
    "csv_path = input(\"Ingrese el path del dataset CSV: \") \n",
    "csv_path = f'CSV/{csv_path}'\n",
    "X, y = load_dataset(csv_path)\n",
    "\n",
    "if X is None or y is None:\n",
    "    print(\"No se pudo cargar el dataset. Saliendo...\")\n",
    "    exit()\n",
    "\n",
    "_, num_caracteristicas = X.shape\n",
    "\n",
    "print(\"Número de características:\", num_caracteristicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empieza el entrenamiento...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 5), output.shape=(None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# y_one_hot = to_categorical(y, num_classes=2)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Ahora puedes entrenar el modelo con las etiquetas en formato one-hot\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpieza el entrenamiento...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m historial \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# historial = model.fit(X, y, epochs=1000, verbose=False)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModelo entrenado\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32ma:\\Materias\\Ciclo 6\\Inteligencia Artificial\\Perceptron\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32ma:\\Materias\\Ciclo 6\\Inteligencia Artificial\\Perceptron\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:668\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[1;34m(target, output, from_logits)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[1;32m--> 668\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    669\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    670\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    672\u001b[0m         )\n\u001b[0;32m    674\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[0;32m    675\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    676\u001b[0m )\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 5), output.shape=(None, 2)"
     ]
    }
   ],
   "source": [
    "# Definición del modelo con 5 salidas\n",
    "model = Sequential([\n",
    "    Dense(units=64, activation='relu', input_shape=[num_caracteristicas]),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    # Cambia el número de unidades a 5 para la salida\n",
    "    # Dense(units=1)\n",
    "    Dense(units=2, activation='sigmoid')  # Cambia a 2 unidades aquí\n",
    "    # Dense(units=5, activation='softmax')  # Asegúrate de tener 5 unidades aquí\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    # loss='mean_squared_error',\n",
    "    loss='binary_crossentropy',  # Usa 'binary_crossentropy' para clasificación binaria\n",
    "    # loss='categorical_crossentropy',  # Si es clasificación multiclase, usa 'categorical_crossentropy'\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Suponiendo que 'y' contiene enteros de clases desde 0 hasta 4\n",
    "y_one_hot = to_categorical(y, num_classes=5)\n",
    "# y_one_hot = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Ahora puedes entrenar el modelo con las etiquetas en formato one-hot\n",
    "print('Empieza el entrenamiento...')\n",
    "historial = model.fit(X, y_one_hot, epochs=1000, verbose=False)\n",
    "# historial = model.fit(X, y, epochs=1000, verbose=False)\n",
    "print('Modelo entrenado')\n",
    "\n",
    "plt.xlabel('# Época')\n",
    "plt.ylabel('Magnitud de pérdida')\n",
    "plt.plot(historial.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediccion\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Entrada: [0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1], Predicción: [1. 0. 0. 0. 0.], Valor real: [1. 0. 0. 0. 0.] \n",
      "Entrada: [1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1], Predicción: [0. 1. 0. 0. 0.], Valor real: [0. 1. 0. 0. 0.] \n",
      "Entrada: [1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1], Predicción: [0. 0. 1. 0. 0.], Valor real: [0. 0. 1. 0. 0.] \n",
      "Entrada: [0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0], Predicción: [0. 0. 0. 1. 0.], Valor real: [0. 0. 0. 1. 0.] \n",
      "Entrada: [1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0], Predicción: [0. 0. 0. 0. 1.], Valor real: [0. 0. 0. 0. 1.] \n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones\n",
    "print('Prediccion')\n",
    "# csv_path = input(\"Ingrese el path del dataset CSV: \") \n",
    "# csv_path = f'CSV/{csv_path}'\n",
    "csv_path = f'CSV/vocalest.csv'\n",
    "X_test, y_test = load_dataset(csv_path)\n",
    "\n",
    "# Suponiendo que 'y' contiene enteros de clases desde 0 hasta 4\n",
    "y_test_one_hot = to_categorical(y, num_classes=5)\n",
    "\n",
    "#Predecir\n",
    "predicciones = model.predict(X_test)\n",
    "\n",
    "# Convertir las probabilidades en etiquetas de clase\n",
    "etiquetas_predichas = np.argmax(predicciones, axis=1)\n",
    "\n",
    "predicciones_one_hot = to_categorical(etiquetas_predichas, num_classes=5)\n",
    "\n",
    "# Imprimir las predicciones en formato one-hot\n",
    "for i, prediccion in enumerate(predicciones_one_hot):\n",
    "    print(f\"Entrada: {X_test[i]}, Predicción: {prediccion}, Valor real: {y_test_one_hot[i]} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
